{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since GitHub wouldn't let us upload all of the CSVs once we unarchived the zip file, we had to use GitHub Large File Storage and we opted to extract the files at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "zip = ZipFile('Resources/archive.zip')\n",
    "zip.extractall('Resources')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the files in the `Resources` folder. Our analysis will start with the Mutual Fund files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"Resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show all columns in each of the DataFrames to help us make some determinations in which columns we will keep and / or lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display all the columns (to see which to drop)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In CSV data for Mutual Fund prices A-Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the CSV files came in 4 pieces, we will read them individually into DataFrames, then combine at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in CSV data \n",
    "#MutualFund prices A-E\n",
    "df_AE= pd.read_csv(\n",
    "    Path(\"Resources/MutualFund Prices - A-E.csv\")\n",
    ")\n",
    "df_AE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in CSV data \n",
    "#MutualFund prices F-K\n",
    "df_FK= pd.read_csv(\n",
    "    Path(\"Resources/MutualFund Prices - F-K.csv\")\n",
    ")\n",
    "df_FK.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in CSV data \n",
    "#MutualFund prices L-P\n",
    "df_LP= pd.read_csv(\n",
    "    Path(\"Resources/MutualFund Prices - L-P.csv\")\n",
    ")\n",
    "df_LP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in CSV data \n",
    "#MutualFund prices Q-Z\n",
    "df_QZ= pd.read_csv(\n",
    "    Path(\"Resources/MutualFund Prices - Q-Z.csv\")\n",
    ")\n",
    "df_QZ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatonate dataframes\n",
    "mutual_fund_df= pd.concat([df_AE,df_FK,df_LP,df_QZ])\n",
    "mutual_fund_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_fund_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to date\n",
    "mutual_fund_df[\"price_date\"]=pd.to_datetime(mutual_fund_df['price_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_fund_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_fund_df.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are no NULLs in the `mutual_fund_df` DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Mutual Fund informaiton csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in CSV data \n",
    "#MutualFunds\n",
    "mutualFunds= pd.read_csv(\n",
    "    Path(\"Resources/MutualFunds.csv\"),\n",
    "    index_col=\"fund_symbol\")\n",
    "\n",
    "mutualFunds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with only 1 value to drop\n",
    "mutualFunds.loc[: , mutualFunds.dtypes== \"object\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 columns currently listed as objects that are actually dates. We need to convert those into dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to date\n",
    "mutualFunds[\"management_start_date\"] = pd.to_datetime(mutualFunds[\"management_start_date\"])\n",
    "mutualFunds[\"inception_date\"] = pd.to_datetime(mutualFunds[\"inception_date\"])\n",
    "mutualFunds[\"returns_as_of_date\"] = pd.to_datetime(mutualFunds[\"returns_as_of_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also noticed that there are 6 columns that have only 1 unique value. We will remove those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds_counts= mutualFunds.loc[: ,mutualFunds.dtypes==\"object\"].nunique()\n",
    "mutualFunds_counts_one= mutualFunds_counts[mutualFunds_counts == 1].index.to_list()\n",
    "print(mutualFunds_counts_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with only 1 unique value\n",
    "mutualFunds.drop(columns=mutualFunds_counts_one,inplace=True)\n",
    "mutualFunds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We noticed that there are many `NaN` values throughout the data set. We will now explore which columns/rows have NaN and will remove an appropriate amount of columns/rows._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we drop rows that have an `NaN`, then all data is removed. Instead, let's look at the columns that have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at each column and the count of NaN in each column\n",
    "list = []\n",
    "for index, row in pd.DataFrame(mutualFunds.isna().sum()).iterrows():\n",
    "    list.append((index,row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to find the number of columns that have above a certain percentage of `NaN` and then remove those columns. We have chosen 60% so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6*len(mutualFunds)\n",
    "drop_columns = []\n",
    "for i in list:\n",
    "    if i[1][0] >= threshold:\n",
    "        drop_columns.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(drop_columns))\n",
    "drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.drop(columns=drop_columns, inplace = True)\n",
    "mutualFunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with too many unique values, and to drop them\n",
    "mutualFunds.loc[: , mutualFunds.dtypes== \"object\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[[\"fund_short_name\", \"fund_long_name\",\"management_name\", \"management_bio\", \"investment_strategy\", \"top10_holdings\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of those 6 columns are long text values. We've decided to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "mutualFunds.drop(columns=[\"fund_short_name\", \"fund_long_name\",\"management_name\", \"management_bio\", \"investment_strategy\", \"top10_holdings\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now remove the numerical columns that have some type of redundant data. This includes quarterly data, and any analytical data. The intent here is to remove as many columns as possible since we currently have over 23K rows of data. If the model does not perform as well as we might hope, then we can return and keep some (if not all) of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove quarterly data\n",
    "mutualFunds.drop(columns=[\"fund_return_2021_q1\",\n",
    "    \"fund_return_2020_q4\",\"fund_return_2020_q3\",\"fund_return_2020_q2\",\"fund_return_2020_q1\",\n",
    "    \"fund_return_2019_q4\",\"fund_return_2019_q3\",\"fund_return_2019_q2\",\"fund_return_2019_q1\",\n",
    "    \"fund_return_2018_q4\",\"fund_return_2018_q3\",\"fund_return_2018_q2\",\"fund_return_2018_q1\",\n",
    "    \"fund_return_2017_q4\",\"fund_return_2017_q3\",\"fund_return_2017_q2\",\"fund_return_2017_q1\",\n",
    "    \"fund_return_2016_q4\",\"fund_return_2016_q3\",\"fund_return_2016_q2\",\"fund_return_2016_q1\",\n",
    "    \"fund_return_2015_q4\",\"fund_return_2015_q3\",\"fund_return_2015_q2\",\"fund_return_2015_q1\",\n",
    "    \"fund_return_2014_q4\",\"fund_return_2014_q3\",\"fund_return_2014_q2\",\"fund_return_2014_q1\",\n",
    "    \"fund_return_2013_q4\",\"fund_return_2013_q3\",\"fund_return_2013_q2\",\"fund_return_2013_q1\",\n",
    "    \"fund_return_2012_q4\",\"fund_return_2012_q3\",\"fund_return_2012_q2\",\"fund_return_2012_q1\",\n",
    "    \"fund_return_2011_q4\",\"fund_return_2011_q3\",\"fund_return_2011_q2\",\"fund_return_2011_q1\",\n",
    "    \"fund_return_2010_q4\",\"fund_return_2010_q3\",\"fund_return_2010_q2\",\"fund_return_2010_q1\",\n",
    "    \"fund_return_2009_q4\",\"fund_return_2009_q3\",\"fund_return_2009_q2\",\"fund_return_2009_q1\",\n",
    "    \"fund_return_2008_q3\",\"fund_return_2008_q2\",\"fund_return_2008_q1\",\n",
    "    \"fund_alpha_3years\",\"fund_beta_3years\",\"fund_mean_annual_return_3years\",\"fund_r_squared_3years\",\"fund_stdev_3years\",\"fund_sharpe_ratio_3years\",\"fund_treynor_ratio_3years\",\n",
    "    \"fund_alpha_5years\",\"fund_beta_5years\",\"fund_mean_annual_return_5years\",\"fund_r_squared_5years\",\"fund_stdev_5years\",\"fund_sharpe_ratio_5years\",\"fund_treynor_ratio_5years\",\n",
    "    \"fund_alpha_10years\",\"fund_beta_10years\",\"fund_mean_annual_return_10years\",\"fund_r_squared_10years\",\"fund_stdev_10years\",\"fund_sharpe_ratio_10years\",\"fund_treynor_ratio_10years\",\n",
    "    \"fund_return_category_rank_ytd\",\"fund_return_category_rank_1month\",\"fund_return_category_rank_3months\",\"fund_return_category_rank_1year\",\"fund_return_category_rank_3years\",\n",
    "    \"fund_return_category_rank_5years\",\"load_adj_return_1year\",\"load_adj_return_3years\",\"load_adj_return_5years\",\"load_adj_return_10years\"],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove metrics that we can caluclate ourselves\n",
    "#keep: \"esg_score\",\"environment_score\", \"sustainability_score\", \"sustainability_rank\",   \"social_score\",  \"governance_score\", \n",
    "mutualFunds.drop(columns=[\"esg_peer_count\",\"peer_esg_min\", \"peer_esg_avg\", \"peer_esg_max\",\n",
    "    \"peer_environment_min\", \"peer_environment_avg\", \"peer_environment_max\", \n",
    "    \"peer_social_min\", \"peer_social_avg\", \"peer_social_max\",\n",
    "    \"peer_governance_min\", \"peer_governance_avg\", \"peer_governance_max\"],\n",
    "    inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.loc[: , mutualFunds.dtypes== \"object\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current DataFrame shape: {mutualFunds.shape}\")\n",
    "print(f\"If we dropped NAs now DataFrame shape: {mutualFunds.dropna().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to remove all `NULL`s at this point, there would be very few rows remaining. For numerical columns, we will replace the `NULL`s will the overall columns' average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average for each column\n",
    "column_means = mutualFunds.mean(skipna=True, numeric_only=True)\n",
    "# Replace NaN values in each column with the respective column average\n",
    "mutualFunds.fillna(column_means, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.dropna(inplace= True)\n",
    "mutualFunds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By replacing the `NULL`s with the column means and then dropping `NULL`s, we have keep over 50% of the rows and all of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.loc[:,mutualFunds.dtypes == \"object\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning `fund_category`. It currently has 91 unique values and here are the value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"fund_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_category_type_count = mutualFunds[\"fund_category\"].value_counts()[mutualFunds[\"fund_category\"].value_counts() > 150]\n",
    "print(100*fund_category_type_count.sum()/len(mutualFunds))\n",
    "print(fund_category_type_count.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the cut-off value at 150, we only have 31 unique values and will keep ~85% of the values before changing the rest to \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in mutualFunds[\"fund_category\"]:\n",
    "    if cat in fund_category_type_count.index.to_list():\n",
    "        next\n",
    "    else:\n",
    "        mutualFunds[\"fund_category\"] = mutualFunds[\"fund_category\"].replace(cat, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"fund_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning `fund_family`. It currently has 310 unique values and here are the value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"fund_family\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_family_type_count = mutualFunds[\"fund_family\"].value_counts()[mutualFunds[\"fund_family\"].value_counts() > 150]\n",
    "print(100*fund_family_type_count.sum()/len(mutualFunds))\n",
    "print(fund_family_type_count.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the cut-off value at 150, we only have 19 unique values and will keep ~64% of the values before changing the rest to \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in mutualFunds[\"fund_family\"]:\n",
    "    if cat in fund_family_type_count.index.to_list():\n",
    "        next\n",
    "    else:\n",
    "        mutualFunds[\"fund_family\"] = mutualFunds[\"fund_family\"].replace(cat, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"fund_family\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns `investment_type` and `size_type` both have 3 unique values. We will keep those as is and not bin them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning `esg_peer_group`. It currently has 310 unique values and here are the value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"esg_peer_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding threshhold to bin esg_peer_group\n",
    "esg_peer_type_count = mutualFunds[\"esg_peer_group\"].value_counts()[mutualFunds[\"esg_peer_group\"].value_counts() > 100]\n",
    "print(100* esg_peer_type_count.sum()/len(mutualFunds))\n",
    "print(esg_peer_type_count.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the cut-off value at 100, we only have 36 unique values and will keep ~89% of the values before changing the rest to \"Other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the bins of esg_peer_group\n",
    "esg_peer_type_count.index.to_list()\n",
    "#replace bins in dataframe for esg_peer_group\n",
    "for esg in mutualFunds[\"esg_peer_group\"]:\n",
    "    if esg in esg_peer_type_count.index.to_list():\n",
    "        next\n",
    "    else:\n",
    "        mutualFunds[\"esg_peer_group\"] = mutualFunds[\"esg_peer_group\"].replace(esg, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"esg_peer_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
